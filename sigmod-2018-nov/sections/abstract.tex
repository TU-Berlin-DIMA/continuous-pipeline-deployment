\begin{abstract}
A machine learning pipeline is a workflow comprised of several steps: source selection, data preparation, feature engineering, and model training. 
Once the model is trained, the model (and the pipeline) is deployed into a system where it can answer prediction queries reliably and in real-time.
Current deployment systems perform online training, periodical batch training, or a combination of both to maintain the quality of the model.
However, the batch training of models is a time-consuming and resource-intensive process.

We propose a novel deployment platform for serving and continuously updating machine learning models and pipelines.
The deployment platform offers two key optimizations: proactive mini-batch training and hybrid (online and offline) pipeline training.
We show that, our deployment platform manages to update the pipeline more frequently while using less resources.
As a result, the accuracy and latency of prediction queries are improved \hl{x times} by using \hl{y times} less resources.
\end{abstract}
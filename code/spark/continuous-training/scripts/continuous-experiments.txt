#!/usr/bin/env bash

CLUSTER :

CRITEO:
/share/hadoop/behrouz/spark/stable/bin/spark-submit --class de.dfki.classification.ContinuousClassifier --master "spark://cloud-11.dima.tu-berlin.de:7077" /share/hadoop/behrouz/jars/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "slack=50" "incremental=true" "error-type=cumulative"  "initial-training-path=hdfs://cloud-11:44000/user/behrouz/criteo/initial-training" "streaming-path=hdfs://cloud-11:44000/user/behrouz/criteo/stream-training" "temp-path=hdfs://cloud-11:44000/user/behrouz/criteo/temp-data" "result-path=/share/hadoop/behrouz/experiments/criteo/" "num-iterations=500" "offline-step-size=1.0" "online-step-size=1.0"

url: 
/share/hadoop/behrouz/spark/stable/bin/spark-submit  --class de.dfki.classification.ContinuousClassifier --master "spark://cloud-11.dima.tu-berlin.de:7077" --conf spark.driver.maxResultSize=10g --conf spark.driver.memory=10g /share/hadoop/behrouz/jars/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=4" "slack=40" "incremental=true" "error-type=cumulative" "initial-training-path=hdfs://cloud-11:44000/user/behrouz/url-reputation/initial-training" "streaming-path=hdfs://cloud-11:44000/user/behrouz/url-reputation/stream-training" "temp-path=hdfs://cloud-11:44000/user/behrouz/url-reputation/temp-data" "result-path=/share/hadoop/behrouz/experiments/url-reputation/" "num-iterations=500" "input-format=svm" "feature-size=3231961" "offline-step-size=1.0" "online-step-size=0.1" "continuous-step-size=0.2"


higgs:
/share/hadoop/behrouz/spark/stable/bin/spark-submit  --class de.dfki.classification.ContinuousClassifier --master "spark://cloud-11.dima.tu-berlin.de:7077" /share/hadoop/behrouz/jars/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "slack=100" "incremental=true" "error-type=cumulative" "initial-training-path=hdfs://cloud-11:44000/user/behrouz/higgs/initial-training" "streaming-path=hdfs://cloud-11:44000/user/behrouz/higgs/stream-training" "temp-path=hdfs://cloud-11:44000/user/behrouz/higgs/temp-data" "result-path=/share/hadoop/behrouz/experiments/higgs/" "num-iterations=1000" "offline-step-size=1.0" "online-step-size=0.1" "continuous-step-size=1.0"

susy:
/share/hadoop/behrouz/spark/stable/bin/spark-submit  --class de.dfki.classification.ContinuousClassifier --master "spark://cloud-11.dima.tu-berlin.de:7077" /share/hadoop/behrouz/jars/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "slack=10" "incremental=true" "error-type=cumulative" "initial-training-path=hdfs://cloud-11:44000/user/behrouz/susy/initial-training" "streaming-path=hdfs://cloud-11:44000/user/behrouz/susy/stream-training" "temp-path=hdfs://cloud-11:44000/user/behrouz/susy/temp-data" "result-path=/share/hadoop/behrouz/experiments/susy/" "num-iterations=500"

***** Local *****: 

criteo-sample: 
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.ContinuousClassifier --master "spark://berlin-189.b.dfki.de:7077" /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "slack=2" "incremental=true" "error-type=cumulative" "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-sample/initial-training" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-sample/stream-training" "temp-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-sample/temp-data" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/criteo-sample/" "num-iterations=200"

cover-type:
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.ContinuousClassifier --master "spark://berlin-187.b.dfki.de:7077" --executor-memory 5G /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "slack=10" "incremental=true" "error-type=cumulative"  "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/cover-types/initial-training" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/cover-types/stream-training" "temp-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/cover-types/temp-data" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/cover-types/" "num-iterations=500" "offline-step-size=1.0" "online-step-size=0.1" "continuous-step-size=1.0"

sea:
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.ContinuousClassifier --master "spark://berlin-187.b.dfki.de:7077" --executor-memory 5G /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "slack=10" "incremental=true" "error-type=cumulative"  "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/sea/initial-training" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/sea/stream-training" "temp-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/sea/temp-data" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/sea/" "num-iterations=500" "offline-step-size=1.0" "online-step-size=0.1" "continuous-step-size=0.01"

HIGGS
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.ContinuousClassifier --master "spark://berlin-241.b.dfki.de:7077" --executor-memory 5G /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "slack=20" "incremental=true" "error-type=cumulative" "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/higgs/initial-training" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/higgs/stream-training" "temp-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/higgs/temp-data" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/higgs/" "num-iterations=500" "offline-step-size=1.0" "online-step-size=1.0"

url-sample: 
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.ContinuousClassifier --master "spark://berlin-241.b.dfki.de:7077" --executor-memory 5G /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "slack=5" "incremental=true" "error-type=cumulative" "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/url-reputation-sample/initial-training" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/url-reputation-sample/stream-training" "temp-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/url-reputation-sample/temp-data" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/url-reputation-sample/" "num-iterations=500" "input-format=svm" "feature-size=3231961" "offline-step-size=1.0" "online-step-size=0.1"

susy:
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.ContinuousClassifier --master "spark://MacBook-Pro-3.local:7077" --executor-memory 5G /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "slack=5" "incremental=true" "error-type=cumulative" "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/susy/initial-training" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/susy/day-based/*" "temp-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/susy/temp-data" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/susy/" "num-iterations=500" "offline-step-size=1.0" "online-step-size=1.0"

Adult: 
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.ContinuousClassifier --master "spark://MacBook-Pro-3.home:7077" /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "slack=10" "incremental=true" "error-type=cumulative" "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/adult/initial-training" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/adult/stream-training" "temp-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/adult/temp-data" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/adult/" "num-iterations=500" "input-format=svm" "feature-size=123" "offline-step-size=1.0" "online-step-size=0.1" "continuous-step-size=1.0"

criteo-full*: 
~/Documents/frameworks/spark/2.2.0/bin/spark-submit --class de.dfki.deployment.ContinuousClassifier --master "spark://berlin-230.b.dfki.de:7077" --executor-memory 5G /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=5" "slack=20" "incremental=true" "error-type=cumulative" "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-full/initial-training/0" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-full/processed/*" "temp-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-full/temp-data" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/criteo-full" "num-iterations=500" "input-format=vector" "offline-step-size=1.0" "model-type=lr" "online-step-size=0.05" "model-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/criteo-full/continuous/model" "continuous-step-size=1.0"

~/Documents/frameworks/spark/2.2.0/bin/spark-submit --class de.dfki.deployment.classifiers.ContinuousClassifier --master "spark://berlin-177.b.dfki.de:7077" --driver-memory 3g --executor-memory 5G /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "slack=10" "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-full/experiments/initial-training/0" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-full/experiments/stream/*" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/criteo-full" "test-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-full/experiments/evaluation/6" "slack=5"

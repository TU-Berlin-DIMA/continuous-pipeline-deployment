#!/usr/bin/env bash

CLUSTER :

CRITEO:
/share/hadoop/behrouz/spark/stable/bin/spark-submit --class de.dfki.classification.VeloxClassifier --master "spark://cloud-11.dima.tu-berlin.de:7077" /share/hadoop/behrouz/jars/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "slack=750" "incremental=true" "error-type=cumulative"  "initial-training-path=hdfs://cloud-11:44000/user/behrouz/criteo/initial-training" "streaming-path=hdfs://cloud-11:44000/user/behrouz/criteo/stream-training" "temp-path=hdfs://cloud-11:44000/user/behrouz/criteo/temp-data" "result-path=/share/hadoop/behrouz/experiments/criteo/" "num-iterations=100"



Local: 
Cover-types: 
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.VeloxClassifier --master "spark://berlin-189.b.dfki.de:7077" target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "slack=50" "result-path=results/cover-types/velox" "initial-training-path=data/cover-types/initial-training" "streaming-path=data/cover-types/stream-training" "temp-path=data/cover-types/temp-data"

criteo-sample:
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.VeloxClassifier --master "spark://berlin-189.b.dfki.de:7077" /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "slack=33" "incremental=true" "error-type=cumulative"  "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-sample/initial-training" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-sample/stream-training" "temp-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-sample/temp-data" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/criteo-sample/" "num-iterations=500"

cover-types:
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.VeloxClassifier --master "spark://MacBook-Pro-3.home:7077" /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "slack=20" "incremental=true" "error-type=cumulative" "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/cover-types/initial-training" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/cover-types/stream-training" "temp-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/cover-types/temp-data" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/cover-types/" "num-iterations=200"


sea:
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.VeloxClassifier --master "spark://berlin-189.b.dfki.de:7077" /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "slack=33" "incremental=true" "error-type=cumulative"  "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/sea/initial-training" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/sea/stream-training" "temp-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/sea/temp-data" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/sea/" "num-iterations=200"
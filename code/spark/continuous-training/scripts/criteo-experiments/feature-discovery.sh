# Local
~/Documents/frameworks/spark/2.2.0/bin/spark-submit --class de.dfki.experiments.FeatureDiscoveryDayByDay --master "spark://dhcp-213-34.vpn.tu-berlin.de:7077" --driver-memory 3g --executor-memory 5G /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "input=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-full/experiments/initial-training/0,/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-full/experiments/stream/1,/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-full/experiments/stream/2,/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-full/experiments/stream/3,/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-full/experiments/stream/4,/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-full/experiments/stream/5" "result=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/criteo-full/feature-discovery/counts" "features=300000000"

# Cluster:
/share/hadoop/behrouz/spark/stable/bin/spark-submit --class de.dfki.experiments.FeatureDiscoveryDayByDay --master "spark://cloud-11.dima.tu-berlin.de:7077" /share/hadoop/behrouz/jars/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "input=hdfs://cloud-11:44000/user/behrouz/criteo/experiments/initial-training/day_0/,hdfs://cloud-11:44000/user/behrouz/criteo/experiments/stream/day_1/,hdfs://cloud-11:44000/user/behrouz/criteo/experiments/stream/day_2,hdfs://cloud-11:44000/user/behrouz/criteo/experiments/stream/day_3,hdfs://cloud-11:44000/user/behrouz/criteo/experiments/stream/day_5" "result=/share/hadoop/behrouz/experiments/criteo-full/feature-discovery/counts" "delimiter=\t" "features=300000000"
#local
~/Documents/frameworks/spark/2.2.0/bin/spark-submit --class de.dfki.experiments.TrainPipeline --master "spark://berlin-177.b.dfki.de:7077" --driver-memory 3g --executor-memory 5G /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "input=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-full/experiments/initial-training/day_0" "result=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/criteo-full/pipelines/test-pipeline/quality" "features=3000" "iterations=500" "pipeline=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/criteo-full/pipelines/test-pipeline/pipeline" "evaluation=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-full/experiments/evaluation/6"


# cluster
/share/hadoop/behrouz/spark/stable/bin/spark-submit --class de.dfki.experiments.TrainPipeline --master "spark://cloud-11.dima.tu-berlin.de:7077" /share/hadoop/behrouz/jars/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "input=hdfs://cloud-11:44000/user/behrouz/criteo/experiments/initial-training/day_0" "result=/share/hadoop/behrouz/experiments/pipelines/test-pipeline/quality" "delimiter=\t" "features=3000" "evaluation=hdfs://cloud-11:44000/user/behrouz/criteo/experiments/evaluation/sample_6/" "iterations=500" "pipeline=/share/hadoop/behrouz/experiments/pipelines/test-pipeline/pipeline" 
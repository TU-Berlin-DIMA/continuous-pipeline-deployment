
# Local: 
~/Documents/frameworks/spark/2.2.0/bin/spark-submit --class de.dfki.experiments.ParameterSelection --master "spark://dhcp-214-87.vpn.tu-berlin.de:7077" --driver-memory 3g --executor-memory 5G /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "updater=rmsprop,adadelta,momentum,adam" "input=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-full/experiments/initial-training/day_0" "stream=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-full/experiments/stream" "evaluation=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-full/experiments/evaluation/6" "result=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/criteo-full/learning-rate/local" "slack=5" "features=3000" "day_duration=100" "pipeline=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/criteo-full/learning-rate/local/pipelines" "days=1"

# Cluster:
/share/hadoop/behrouz/spark/stable/bin/spark-submit --class de.dfki.experiments.ParameterSelection --master "spark://cloud-11.dima.tu-berlin.de:7077" /share/hadoop/behrouz/jars/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "updater=rmsprop,adadelta,momentum,adam" "input=hdfs://cloud-11:44000/user/behrouz/criteo/experiments/initial-training/day_0" "stream=hdfs://cloud-11:44000/user/behrouz/criteo/experiments/stream" "evaluation=hdfs://cloud-11:44000/user/behrouz/criteo/experiments/evaluation/sample_6/" "result=/share/hadoop/behrouz/experiments/criteo-full/learning-rate/cluster" "delimiter=\t" "features=3000" "pipeline=/share/hadoop/behrouz/experiments/criteo-full/pipelines/learning-rate/cluster/pipelines" "days=1" "day_duration=1440" "updater=rmsprop,adam,adadelta,momentum"
Cluster:
/share/hadoop/behrouz/spark/stable/bin/spark-submit --class de.dfki.classification.InitialClassifier --master "spark://cloud-11.dima.tu-berlin.de:7077" /share/hadoop/behrouz/jars/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "error-type=cumulative"  "initial-training-path=hdfs://cloud-11:44000/user/behrouz/criteo/initial-training" "streaming-path=hdfs://cloud-11:44000/user/behrouz/criteo/stream-training" "temp-path=hdfs://cloud-11:44000/user/behrouz/criteo/temp-data" "result-path=/share/hadoop/behrouz/experiments/criteo/" "num-iterations=200"

URL:
/share/hadoop/behrouz/spark/stable/bin/spark-submit  --class de.dfki.classification.InitialClassifier --master "spark://cloud-11.dima.tu-berlin.de:7077" /share/hadoop/behrouz/jars/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=2" "incremental=true" "error-type=cumulative" "initial-training-path=hdfs://cloud-11:44000/user/behrouz/url-reputation/initial-training" "streaming-path=hdfs://cloud-11:44000/user/behrouz/url-reputation/stream-training" "temp-path=hdfs://cloud-11:44000/user/behrouz/url-reputation/temp-data" "result-path=/share/hadoop/behrouz/experiments/url-reputation/" "num-iterations=100" "input-format=svm" "feature-size=3231961"

Local:
Criteo sample:
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.InitialClassifier --master "spark://berlin-189.b.dfki.de:7077" /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "error-type=cumulative"  "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-sample/initial-training" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-sample/stream-training" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/criteo-sample/" "num-iterations=500"

cover-types:
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.InitialClassifier --master "spark://MacBook-Pro-3.home:7077" /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "error-type=cumulative"  "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/cover-types/initial-training" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/cover-types/stream-training" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/cover-types/" "num-iterations=200"

sea:
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.InitialClassifier --master "spark://berlin-189.b.dfki.de:7077" /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "error-type=cumulative"  "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/sea/initial-training" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/sea/stream-training" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/sea/" "num-iterations=500"
#!/usr/bin/env bash

Cluster:
/share/hadoop/behrouz/spark/stable/bin/spark-submit --class de.dfki.classification.InitialClassifier --master "spark://cloud-11.dima.tu-berlin.de:7077" /share/hadoop/behrouz/jars/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "error-type=cumulative"  "initial-training-path=hdfs://cloud-11:44000/user/behrouz/criteo/initial-training" "streaming-path=hdfs://cloud-11:44000/user/behrouz/criteo/stream-training" "temp-path=hdfs://cloud-11:44000/user/behrouz/criteo/temp-data" "result-path=/share/hadoop/behrouz/experiments/criteo/" "num-iterations=200"

URL:
/share/hadoop/behrouz/spark/stable/bin/spark-submit  --class de.dfki.classification.InitialClassifier --master "spark://cloud-11.dima.tu-berlin.de:7077" /share/hadoop/behrouz/jars/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=2" "incremental=true" "error-type=cumulative" "initial-training-path=hdfs://cloud-11:44000/user/behrouz/url-reputation/initial-training" "streaming-path=hdfs://cloud-11:44000/user/behrouz/url-reputation/stream-training" "temp-path=hdfs://cloud-11:44000/user/behrouz/url-reputation/temp-data" "result-path=/share/hadoop/behrouz/experiments/url-reputation/" "num-iterations=500" "input-format=svm" "feature-size=3231961" "offline-step-size=1.0"

higgs:
/share/hadoop/behrouz/spark/stable/bin/spark-submit  --class de.dfki.classification.InitialClassifier --master "spark://cloud-11.dima.tu-berlin.de:7077" /share/hadoop/behrouz/jars/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "incremental=true" "error-type=cumulative" "initial-training-path=hdfs://cloud-11:44000/user/behrouz/higgs/initial-training" "streaming-path=hdfs://cloud-11:44000/user/behrouz/higgs/stream-training" "result-path=/share/hadoop/behrouz/experiments/higgs/" "num-iterations=500" "offline-step-size=1.0"

susy:
/share/hadoop/behrouz/spark/stable/bin/spark-submit  --class de.dfki.classification.InitialClassifier --master "spark://cloud-11.dima.tu-berlin.de:7077" /share/hadoop/behrouz/jars/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "incremental=true" "error-type=cumulative" "initial-training-path=hdfs://cloud-11:44000/user/behrouz/susy/initial-training" "streaming-path=hdfs://cloud-11:44000/user/behrouz/susy/stream-training" "result-path=/share/hadoop/behrouz/experiments/susy/" "num-iterations=500"


Local:
Criteo sample:
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.InitialClassifier --master "spark://berlin-189.b.dfki.de:7077" /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "error-type=cumulative"  "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-sample/initial-training" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-sample/stream-training" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/criteo-sample/" "num-iterations=500"

cover-types:
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.InitialClassifier --master "spark://berlin-187.b.dfki.de:7077" --executor-memory 5G /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "error-type=cumulative"  "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/cover-types/initial-training" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/cover-types/stream-training" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/cover-types/" "num-iterations=500"

sea:
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.InitialClassifier --master "spark://berlin-187.b.dfki.de:7077" --executor-memory 5G /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "error-type=cumulative"  "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/sea/initial-training" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/sea/stream-training" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/sea/" "num-iterations=500" "offline-step-size=1.0" "online-step-size=0.05" "continuous-step-size=0.01"

url-sample: 
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.InitialClassifier --master "spark://MacBook-Pro-3.local:7077" --executor-memory 5G /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "incremental=true" "error-type=cumulative" "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/url-reputation-sample/initial-training" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/url-reputation-sample/stream-training" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/url-reputation-sample/" "num-iterations=500" "input-format=svm" "feature-size=3231961" "offline-step-size=1.0" "online-step-size=0.1"

HIGGS:
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.InitialClassifier --master "spark://berlin-241.b.dfki.de:7077" --executor-memory 5G /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "incremental=true" "error-type=cumulative" "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/higgs/initial-training" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/higgs/stream-training" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/higgs/" "num-iterations=500" "offline-step-size=1.0" "online-step-size=1.0"

susy-sample:
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.InitialClassifier --master "spark://berlin-241.b.dfki.de:7077" --executor-memory 5G /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "incremental=true" "error-type=cumulative" "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/susy/initial-training" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/susy/stream-training" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/susy/" "num-iterations=500" "offline-step-size=1.0" "online-step-size=1.0"

Adult:
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.classification.InitialClassifier --master "spark://berlin-187.b.dfki.de:7077" --executor-memory 5G /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "incremental=true" "error-type=cumulative" "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/adult/initial-training" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/adult/stream-training" "temp-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/adult/temp-data" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/adult/" "num-iterations=500" "input-format=svm" "feature-size=123" "offline-step-size=1.0" "online-step-size=0.1"

criteo-full*:
~/Documents/frameworks/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --class de.dfki.deployment.InitialClassifier --master "spark://berlin-235.b.dfki.de:7077" --executor-memory 5G /Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/target/continuous-training-1.0-SNAPSHOT-jar-with-dependencies.jar "batch-duration=1" "incremental=true" "error-type=cumulative" "initial-training-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-full/initial-training/0" "streaming-path=/Users/bede01/Documents/work/phd-papers/continuous-training/code/spark/continuous-training/data/criteo-full/processed/*" "result-path=/Users/bede01/Documents/work/phd-papers/continuous-training/experiment-results/criteo-full" "num-iterations=500" "input-format=vector" "offline-step-size=1.0" "model-type=lr"


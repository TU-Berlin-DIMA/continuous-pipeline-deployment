\section{Continuous Training and Serving} \label{continuous-training-serving}
To continuously train the deployed model, we rely on computing partial updates based on the current parameters of the model and a combination of the incoming and existing data.
To compute the partial updates, we utilize Stochastic Gradient Descent (SGD) \cite{zhang2004solving}.
SGD algorithm has several parameters and in order to work effectively, they have to be tuned.
In this section, we first describe the details of SGD and its parameters and our approach in tuning these parameters for our platform.
Then we describe how we take advantage of the properties of SGD to implement our proactive training, online statistics computation, and feature materialization.
Another important aspect of any deployment platform is the ability to monitor the quality of the deployed model.
We present our method for evaluating the quality of the deployed model and how we guarantee high-quality models.
Finally, we describe how our continuous training approach improves the efficiency of the deployment process.

\subsection{Stochastic Gradient Descent} \label{sgd}
\textit{Stochastic Gradient Descent (SGD)} is an optimization strategy utilized by many machine learning algorithms for training a model.
SGD is an iterative optimization technique where in every iteration, one data point or a sample of the data points is utilized to update the model.
SGD is suitable for large datasets as it does not require scanning the entire data in every iteration \cite{bottou2010large}.
SGD is used in different machine learning tasks such as classification \cite{zhang2004solving, macmahan2013}, clustering \cite{bottou1995convergence}, and matrix factorization \cite{koren2009matrix,  funk2006netflix}.
It is also widely used in neural networks for training the networks on large datasets \cite{dean2012large}.
Prominent applications of SGD in neural networks are the work of Google Deepmind team that managed to train neural networks that defeat humans in the game of Go \cite{silver2016mastering} and mastering Atari games \cite{mnih2013playing}.

In Section \ref{introduction}, we described how a logistic regression model is utilized to predict the click through rate of different ads.
In logistic regression, the goal is to find the weight vector ($w$) that maximizes the conditional likelihood of labels ($y$) based on the given data ($x$) in the training dataset:

\begin{center}
$w^* = \argmin_w ln(\prod_{i=1}^{N} P(y^i | x^i, w))$
\end{center}

where $N$ is the size of the training dataset.
To utilize SGD for finding the optimal $w$, we start from initial random weights and in each we update the weights based on the gradient of the loss function:

\begin{center}
${w}^{t+1} = {w}^t + \eta \sum_{i \in S} x^i (y^i - \hat{P}(Y^i = 1 | x^i w))$
\end{center}

where $\eta$ is the learning rate parameter and $S$ is the random sample in the current iteration.
The algorithm continues until convergence (when the weight vector does not change after an iteration).

\textbf{Learning Rate.}
A very important parameter of stochastic gradient descent is the learning rate.
The learning rate controls the degree of change in the weights in each iteration of SGD.
The most basic approach of tuning the learning rate is setting it to an initial small value and after each iteration decrease the value by a small factor.
In complex and high-dimensional problems, this simple tuning approach for the learning rate is not effective \cite{schaul2013no}. 
Adaptive learning rate methods such as, Momentum \cite{qian1999momentum}, Adam \cite{kingma2014adam}, RMSPROP \cite{tieleman2012lecture}, and AdaDelta \cite{zeiler2012adaptive} have been proposed.
These methods automatically adjust the learning rate value in every iteration and speed up the convergence time.
Moreover, some of the adaptation methods perform per coordinate modification \cite{schaul2013no, tieleman2012lecture, zeiler2012adaptive}. 
This is important because not all the parameters of the weight vector contribute the same way and some of the parameters change more rapidly during the training process.

\textbf{Sample Size.}
Another parameter of stochastic gradient descent is the sample size.
SGD is guaranteed to converge to a solution regardless of the sample size.
However, the sample size can greatly affect the time that is required to converge.
Two extremes of the sample size are 1 (every iteration only considers 1 data item) and $N$ (every iteration consider the entire data set, similar to normal batch gradient descent).
Setting the sample size to 1 increases the model update frequency, however, it also results in noisy updates.
Therefore, more iterations are required for the model to converge.
Using the entire data in every iteration leads to more stable updates and as a result, the number of iterations required for the model to converge is fewer.
However, each iteration takes more time as more data has to be processed.
The most common approach is to set the sample size to a value small enough so that each sample can be processed quickly but large enough so the updates are not noisy (called a mini-batch gradient descent).

\textbf{Distributed SGD.}
To efficiently train machine learning models on large datasets, scalable techniques have to be employed.
SGD inherently works well with large amounts of data because it does not need to scan every data point during every iteration.
However, for very large datasets, SGD has to perform many iterations in order to converge.
To decrease the running time, large datasets can be distributed among multiple nodes, where each node will compute the gradients on a subset of the data in parallel.
After the initial computation of the gradients, they are all sent to one node where the final gradients are computed.

\subsection{Proactive Training} \label{proactive-training}
Proactive training replaces the periodical offline retraining of the deployed model.
We use the iterative nature of SGD in the design of the proactive training.
The input to each iteration of SGD is the current weights of the model, one or more data points, and an objective function.
In proactive training, we execute iterations of SGD on the deployed model.
The deployment platform, first samples the historical data, then transforms the data using the deployed pipeline.
Next, the proactive trainer uses the resulting data to compute the gradient of the objective function and finally update the deployed model.

The two parameters of SGD (learning rate and sample size) play an important role in proactive training.
They have to be tuned to increase the efficiency of the training.
Choosing  a very small sample size may result in inaccurate updates and as a result, degrade the quality of the deployed model.
On the other hand, a very large sample size leads to a lengthy training process and less frequent model updates.
Similarly, learning rate should be adapted accordingly.
Therefore, the process of choosing the best sample size and learning rate adaptation technique is similar to static training.
Different hyperparameter tuning techniques are proposed for finding the best set of hyperparameters.
Most common and simplest approaches are grid search and random search \cite{bergstra2012random}.
We use a grid search over the initial training data to find the best hyperparameters (in our system, learning rate adaptation technique and sample size).
Once the initial model is trained and deployed, the same set of parameters are used for the proactive training.
In Section \ref{evaluation}, we show that simple hyperparameter tuning methods result in the best set of parameters for the proactive training.
We also show that training a deployed model using the proactive training method results in a similar error rate to the periodical retraining while using fewer resources.

\textit{Model Stability}
To ensure that proactive training does not degrade the quality of the model, a model evaluator is used to assess the quality of the model.
The proactive trainer uses the latest deployed model as an initial starting point and updates the model based on the training data.
The evaluator assesses the quality of the model using an evaluation dataset or the prequential evaluation method \cite{dawid1984present}.
If the quality of the model has degraded, the update is discard and the model is logged.
This is to avoid over training the deployed model in proactive training.

%\todo[inline]{I'm going to remove scheduling rate and just run proactive training when the sample buffer is full}
%\textit{Scheduling rate.}
%\hl{An extra parameter of proactive training is the scheduling rate.
%In offline training, iterations of SGD are executed one after the other until convergence.
%In proactive training, the scheduling rate defines the frequency of SGD iteration execution.
%The scheduling rate plays an important role as it directly affects the freshness of the deployed model.
%However, a high scheduling rate results in many frequent SGD iterations which incur an overhead on the deployment system as it is using a lot of resources.
%A small scheduling rate also affects the model freshness.
%To increase the efficiency of the system a scheduler component is designed that is tasked with scheduling new iterations of SGD.
%Similar to learning rate tuning, we use an adaptive approach to adjust the scheduling rate.
%We describe a method for tuning the scheduling rate based on the rate of the incoming training data.
%The scheduling rate is increased as the rate of the incoming training data increases and vice versa.
%This helps in adapting the model to the new training data.}

\subsection{Online Statistics Computation and Feature Materialization}
Before updating the deployed model using the proactive training, the data has to be processed by the pipeline.
Some components of the machine learning pipeline ,such as standard scaler or one-hot encoder, require statistics over the dataset to be calculated before they process the data.
Computing these statistics require scans of the data.
In our deployment platform, we utilize online training as well as proactive training.
During the online update of the deployed model, we compute all the necessary statistics for every component.
Computing the required statistics online eliminates the need to recompute the statistics for proactive training.

Moreover, during the online learning, the incoming data are transformed to a set of features before updating the model.
Given enough storage space, our deployment platform caches these preprocessed features.
Therefore, while performing the proactive training, instead of sampling from the raw historical data, the deployment platform samples the features directly from the cache.
Caching the features completely eliminates the data preprocessing part of the pipeline during the proactive training and significantly reduces the total time.

\textit{Dynamic model size.}
Depending on the type of the pipeline components, the size of the deployed model may need to be adjusted during the online or proactive training.
For example, one-hot encoding and data bucketization, both may generate new features after processing new training data.
After every statistics update, we analyze the changes made in the pipeline.
If any of the changes result in an increase in the model size, we dynamically adjust the model size in the next proactive training. 


\subsection{Improved Deployment Process}
\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{../images/generic-improved-example-v2.pdf}
\caption{Improved deployment process of machine learning applications}
\label{fig:improved-example}
\end{figure}

Figure \ref{fig:improved-example} shows how our continuous training approach improves the deployment process of machine learning applications.
Similar to the current deployment process, a user first trains a pipeline and deploy it into the deployment platform.
The deployment platform uses the deployed pipeline and model to answer prediction queries and update the model using the incoming training data.
After the incoming training data are preprocessed, they are stored in a cache.
During the proactive training, samples of the features from the cache are used to compute a partial gradient.
The model is then updated using the computed gradient.
In the new workflow, the deployment platform continuously updates the pipeline and the deployed model without requiring a full retraining over historical data.
The deployment platform ensures that the model is always up-to-date.
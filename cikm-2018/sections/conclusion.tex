\section{Conclusions} \label{conclusion}
We propose a deployment platform for continuously updating machine learning pipelines and models.
After a machine learning pipeline is designed and initially trained on a dataset, our platform deploys the pipeline and makes it available for answering prediction queries.

To guarantee a model with an acceptable error rate, existing deployment platforms periodically train the deployed model. 
However, periodical training is a time-consuming and resource-intensive process.
As a result of the lengthy training process, the platform cannot produce fresh models.
This results in model-staleness and a drop in the quality of the deployed model.

We propose a training approach, called proactive training, that utilizes samples of historical data to train the deployed pipeline.
Proactive training replaces the periodical retraining, thus guaranteeing a high-quality model with the lengthy retraining process.
We also propose online statistics computation and materialization of the preprocessed features.
We propose a modular design that enables our deployment platform to be integrated with different scalable data processing platforms.

We implement a prototype using Apache Spark to evaluate the performance of our deployment platform on different datasets.
In our experiments, we develop two pipelines with different machine learning models to process two different datasets.
We discuss how to tune the deployment platform based on the available historical data.
Our experiments show that our continuous deployment reduces the total training cost by a factor $5$ and $13$ for the Taxi and URL datasets, respectively.
Moreover, continuous deployment improves the overall quality of the deployed model when compared with the periodical deployment approach.

In the future work, we will integrate more complex machine learning pipelines (e.g., neural networks) into our deployment platform and investigate the effect of concept drift and anomaly on our deployment platform.


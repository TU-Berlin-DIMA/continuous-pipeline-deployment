\begin{abstract}
Machine learning is increasingly pervasive in many business and scientific applications. 
Making machine learning models ready for serving in a production environment is a process done in form of pipelines steps including source selection, data preparation, feature engineering, and model training. 
Once the model is trained, the model (and the pipeline) is deployed into a system where it can answer prediction queries in real-time.
Current deployment systems perform online training, periodical batch training, or a combination of both to maintain the quality of the model.
\hl{However, training models to meet a high-quality threshold is a time-consuming and resource-intensive process and cannot be performed frequently.
This leads to a trade-off between model freshness (how up-to-date the model is) and model quality.}
\todo[inline]{First, periodical batch retraining leads to high-quality model, right? You mention cost (time, resource) as main issue with retraining.
	Then, I think the trade off is between model quality and cost. How about we focus on showing that while the quality of the model obtained by your approach is better than previous retrained model (if the experiment do not fail us) and very close to a high-quality retrained model, it better in terms of cost. What do you say? Off curse, we have to find a way to show the trade off in the experiment too.}

We propose a novel continuous training approach, for deployed pipelines and models, that increases the model freshness without sacrificing the model quality.
Our approach is similar to how parameter servers are used to train large machine learning models, where several computing nodes calculate partial updates and push them to the model.
In our approach, we compute partial updates as new training data becomes available and propagate the partial updates to the deployed model without requiring a redeployment.
Moreover, we further decrease the training time by computing statistics during model serving.
In our experiments, we show that our continuous training approach updates the model more frequently while using fewer resources which results in an improvement of $1.6\%$ in error rate and up to $2$ orders of magnitude faster than state-of-the-art deployment approaches.
\end{abstract}
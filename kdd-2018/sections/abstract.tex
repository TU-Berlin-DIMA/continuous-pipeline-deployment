\begin{abstract}
\todo[inline]{Pipeline vs model: we should make it clear what do we mean. In this draft, pipeline and model are sometimes synonyms and sometimes have different meanings.}
\todo[inline]{Reformulate the opening statement. Introduce the problem (deployment), discuss why it is important then discuss what are the challenges}
\hl{Machine learning is increasingly pervasive in many business and scientific applications. 
Making machine learning models ready for serving in a production environment is a process done in form of pipelines steps including source selection, data preparation, feature engineering, and model training. 
Once the model is trained, the pipeline is deployed into a system where it can answer prediction queries in real-time.}
In order to maintain the quality of the model, current deployment systems update the deployed model using a combination of online training and periodical retraining. 
While the online training is fast, the retraining of the model is a time-consuming and resource-intensive process.
This leads to a trade-off between the training cost and the model quality.

We propose a novel approach for continuously training and deploying pipelines using both the incoming and the existing historical data.
We offer fast sampling techniques for including the historical data it in the training process, thus eliminating the need for complete retraining of deployed pipeline.
Moreover, we offer two optimization techniques: \textit{live statistics analysis} and \textit{materialization of preprocessed data} to minimize the total training and data preprocessing time.
In our experiments, we show that our continuous training approach updates the model more frequently while using fewer resources which results in an improvement of \hl{$1.6\%$} in error rate and up to \hl{$2$} orders of magnitude faster than state-of-the-art deployment approaches.
\end{abstract}
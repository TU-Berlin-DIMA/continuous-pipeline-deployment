\section{Conclusions} \label{conclusion}
We propose a deployment platform for continuously updating machine learning pipelines and models.
After a machine learning pipeline is designed and initially trained on a dataset, our platform deploys the pipeline and makes it available for answering prediction queries.
\added{To ensure that the model maintains an acceptable error rate}
\deleted{To guarantee a model with an acceptable error rate}
, existing deployment platforms periodically retrain the deployed model.
However, periodical retraining is a time-consuming and resource-intensive process.
As a result of the lengthy training process, the platform cannot produce fresh models.
This results in model-staleness which may decrease the quality of the deployed model.

We propose a training approach, called proactive training, that utilizes samples of the historical data to train the deployed pipeline.
Proactive training replaces the periodical retraining, \added[comment={R2: 6}]{which provides the same level of model quality} \deleted{thus guaranteeing a high-quality model} without the lengthy retraining process.
We also propose online statistics computation and dynamic materialization of the preprocessed features which further decreases the training time.
\deleted{We propose a modular design that enables our deployment platform to be integrated with different scalable data processing platforms.}

We implement a prototype using Apache Spark to evaluate the performance of our deployment platform.
In our experiments, we develop two pipelines with two machine learning models to process two real-world datasets.
We discuss how to tune the deployment platform based on the available historical data.
Our experiments show that our continuous deployment reduces the total deployment cost by a factor of $6$ and $15$ for the Taxi and URL datasets, respectively.
Moreover, continuous deployment platform provides the same level of quality for the deployed model when compared with the periodical deployment approach.

\added[comment=R1:weak-points-2]{We recognize two drawbacks with our current work.
First, we do not tackle the integration of more complex machine learning models (e.g., neural networks).
Second, we only provide support for anomaly and concept drift detection through components of the machine learning pipeline even though they can greatly affect the quality of a deployed model.
In the future work, we plan to integrate more complex machine learning models and provide native support for concept drift and anomaly detection.}
\deleted{
In the future work, we will integrate more complex machine learning pipelines and models (e.g., neural networks) into our deployment platform and investigate the effect of concept drift and anomalies on our deployment platform.}
\newline

\added[comment=acknowledgments]{{\small
\textbf{Acknowledgments.} This work has been supported by the European Commission
through Streamline (ref. 688191) and by the German Ministry for Education and Research by Berlin Big Data Center BBDC (funding mark 01IS14013A) and Berliner Zentrum f√ºr Maschinelles Lernen BZML (funding mark 01IS18037A).}}


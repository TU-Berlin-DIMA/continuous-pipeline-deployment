\section{Background} \label{background}
To continuously train the deployed model, we compute partial updates based on the current model parameters and a combination of the incoming and existing data.
To compute the partial updates, we utilize Stochastic Gradient Descent (SGD) \cite{zhang2004solving}.
SGD has several parameters (typically referred to as hyperparameters) and in order to work effectively, they have to be tuned.
In this section, we describe the details of SGD and its hyperparameters and discuss the effect of the hyperparameters on training machine learning models.

\subsection{Stochastic Gradient Descent} \label{sgd}
\textit{Stochastic Gradient Descent (SGD)} is an optimization strategy utilized by many machine learning algorithms for training a model.
SGD is an iterative optimization technique where in every iteration, one data point or a sample of the data points is utilized to update the model.
SGD is suitable for large datasets as it does not require scanning the entire data in every iteration \cite{bottou2010large}.
SGD is also suitable for online learning scenarios, where new training data becomes available one at a time.
Many different machine learning tasks such as classification \cite{zhang2004solving, macmahan2013}, clustering \cite{bottou1995convergence}, and matrix factorization \cite{koren2009matrix,  funk2006netflix} utilize SGD in training models.
SGD is also the most common optimization strategy for training neural networks on large datasets \cite{dean2012large}.
\deleted[comment={to save space}]{Prominent applications of SGD in neural networks are the work of Google Deepmind team that managed to train neural networks that defeat humans in the game of Go \cite{silver2016mastering} and mastering Atari games \cite{mnih2013playing}.}

\added[comment={R2:7}]{To explain the details of SGD, we describe how it is utilized to train a simple linear regression model.
In linear regression, the goal is to find the weight vector($w$) that minimizes the least-squares cost function ($J(w)$): }
\deleted{To explain the details of SGD, we describe how it is utilized to train a logistic regression model.
In logistic regression, the goal is to find the weight vector ($w$) that maximizes the conditional likelihood of labels ($y$) based on the given data ($x$) in the training dataset:}
\todo[inline]{switched the formula from logistic regression to linear regression, since it is easier to understand how we get to the final update rule without stating intermediate steps}
\begin{equation}
\added{J(w)=\dfrac{1}{2}\sum_{i=1}^{N}(x^iw - y^i)^2}
\end{equation}
%\begin{equation}
%w^* = \argmax_w \sum_{i=1}^{N} ln(P(y^i | x^i, w))
%\end{equation}

where $N$ is the size of the training dataset.
To utilize SGD for finding the optimal $w$, we start from initial random weights.
Then in every iteration, we update the weights based on the gradient of the loss function:

\begin{equation}
\added{{w}^{t+1} = {w}^t + \eta \sum_{i \in S} (y^i - x^iw)x^i}
\end{equation}

%\begin{equation}
%{w}^{t+1} = {w}^t + \eta \sum_{i \in S} x^i (y^i - \hat{P}(Y^i = 1 | x^i w))
%\end{equation}

where $\eta$ is the learning rate hyperparameter and $S$ is the random sample in the current iteration.
The algorithm continues until convergence, i.e., when the weight vector does not change after an iteration.

\textbf{Learning Rate.}
An important hyperparameter of stochastic gradient descent is the learning rate.
The learning rate controls the degree of change in the weights during every iteration.
The most trivial approach for tuning the learning rate is to initialize it to a small value and after every iteration decrease the value by a small factor.
However, in complex and high-dimensional problems, the simple tuning approach is ineffective \cite{schaul2013no}. 
Adaptive learning rate methods such as Momentum \cite{qian1999momentum}, Adam \cite{kingma2014adam}, Rmsprop \cite{tieleman2012lecture}, and AdaDelta \cite{zeiler2012adadelta} have been proposed.
These methods adaptively adjust the learning rate in every iteration to speed up the convergence rate.
Moreover, some of the learning rate adaptation methods perform per coordinate modification, i.e., every parameter of the model weight vector is adjusted separately from the others \cite{kingma2014adam, tieleman2012lecture, zeiler2012adadelta}. 
In many high-dimensional problems, the parameters of the weight vector do not have the same level of importance, therefore each parameter must be treated differently during the training process.

\textbf{Sample Size.}
Another hyperparameter of stochastic gradient descent is the sample size (sometimes referred to as the mini-batch size).
Given proper learning rate tuning mechanism, SGD eventually converges to a solution regardless of the sample size.
However, the sample size can greatly affect the time that is required to converge.
Two extremes of the sample size are 1 (every iteration considers 1 data item) and $N$ (similar to batch gradient descent, every iteration scans the entire dataset).
Setting the sample size to 1 increases the model update frequency but results in noisy updates.
Therefore, more iterations are required for the model to converge.
Using the entire data in every iteration leads to more stable updates.
As a result, the model training process requires fewer iterations to converge.
However, because of the size of the data, individual iterations require more time to complete.
A common approach is mini-batch gradient descent.
In mini-batch gradient descent, the sample size is selected in such a way that each iteration is fast.
Moreover, the training process requires fewer iterations to converge.

\deleted[comment={R2:8}]{
\textbf{Distributed SGD.}
To efficiently train machine learning models on large datasets, one has to employ scalable training algorithms.
SGD inherently works well with large datasets because it does not need to scan every data point during every iteration.
However, SGD has to perform many iterations to converge.
To decrease the execution time, one can distribute the large dataset among multiple nodes.
During the training, each node computes a partial gradient on a subset of the data in parallel.
After this step, all the partial gradients are combined to compute the final gradient.
Distributed SGD significantly reduces the time for executing individual iterations, which results in a reduction in the overall training time.}

\subsection{Tuning the Periodical Deployment}
Typically, two groups of hyperparameters affect the efficiency of the periodical deployment approach.
The first group (the deployment hyperparameters) control the frequency and amount of data for every retraining.
The second group (the training hyperparameters) tune the algorithm for retraining procedure.
In this work, we are targeting training algorithms based on Stochastic gradient descent.
Therefore, the hyperparameters are the learning rate and the sample size.

There are several existing approaches for tuning the training hyperparameters, such as grid search, random search, and sequential model based search \cite{bergstra2012random,hutter2011sequential}.
The deployment hyperparameters, however, are typically selected to fit the specific use case.
For example, in many of the real-world use cases, one retrains the deployed model using the entire historical data \added[comment={R2:9}]{(hyperparameter for the amount of data for every retraining)} on a daily basis \added[]{(hyperparameter for the frequency of the retraining)}.
\deleted[]{Similarly, when tuning our continuous deployment platform, one has to select two hyperparameters which vary from use-case to use-case.}
In the next sections, \deleted{we show that tuning our continuous deployment approach is no more complex than tuning the periodical deployment approach.}\added{we describe how we tune the deployment and training hyperparameters of our deployment framework.}

